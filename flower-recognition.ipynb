{"cells":[{"metadata":{},"cell_type":"markdown","source":"**ABOUT THE DATA**\n\nThis dataset contains 4242 images of flowers.\nThe data collection is based on the data flicr, google images, yandex images.\nYou can use this datastet to recognize plants from the photo.\n\nThe pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.\nFor each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!\n\n**Please, upvote if you like and comment below :)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Read Data\nimport os\nimport cv2\nimport numpy as np\n\n#Encoding and Split data into Train/Test Sets\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n#Tensorflow Keras CNN Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\n#Plot Images\nimport matplotlib.pyplot as plt\n\n\nfolder_dir = '/kaggle/input/flowers-recognition/flowers/flowers/'\nprint(os.listdir(folder_dir))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Read every image in the data end create a lable for each with the folder name\n\ndata = []\nlabel = []\n\nSIZE = 128 #Crop the image to 128x128\n\nfor folder in os.listdir(folder_dir):\n    for file in os.listdir(os.path.join(folder_dir, folder)):\n        if file.endswith(\"jpg\"):\n            label.append(folder)\n            img = cv2.imread(os.path.join(folder_dir, folder, file))\n            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            im = cv2.resize(img_rgb, (SIZE,SIZE))\n            data.append(im)\n        else:\n            continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#See shape of data: 4323 images, each 128x128 and 3 color channels RGB\ndata_arr = np.array(data)\nlabel_arr = np.array(label)\n\nprint(data_arr.shape, label_arr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-Hot encoding the labels and normalize image data\nencoder = LabelEncoder()\ny = encoder.fit_transform(label_arr)\ny = to_categorical(y,5)\nX = data_arr/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data into Train/Test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Shape\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(5, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Augmentation, create more training images to prevent overfitting\ndatagen = ImageDataGenerator(\n        rotation_range=20,\n        zoom_range = 0.20,\n        width_shift_range=0.3,\n        height_shift_range=0.3,\n        horizontal_flip=True,\n        vertical_flip=True)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\nepochs=64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs,\n                              validation_data = (X_test,y_test),\n                              verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the Graph showing how Test/Train scores curve\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(15,6))\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Model Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['train', 'test'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'test'], loc='upper left')\nprint(\"As we can see, the training and test values follow the same pattern of growth or decay, showing that there is no overfitting\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = np.sort(os.listdir(folder_dir))\ncategories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let's see some classifications\nfig, ax = plt.subplots(6,6, figsize=(25, 40))\n\nfor i in range(6):\n    for j in range(6):\n        k = int(np.random.random_sample() * len(X_test))\n        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n        else:\n            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thanks, upvote if you liked :)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}